"""
This script downloads the repology.json file and compiles a unique
set of CPE strings which will be used to query the CVE databases.
The results are pushed into a database with a last-seen timestamp.


Copyright (c) 2025, The Ravenports Project.

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
"""

import os
import json
import urllib.request

DPATH = os.path.dirname(__file__)
ETAG_CACHE_FILE = os.path.join(DPATH, ".cached_etag")
REPOLOGY_FILE = os.path.join(DPATH, ".repology.json")


def get_cached_etag():
    """
    Returns stored etag or none
    """

    try:
        with open(ETAG_CACHE_FILE, "r", encoding="utf-8") as fin:
            return fin.read()
    except IOError:
        return None


def write_etag_cache(etag):
    """
    Procedure to write etag to cache
    """
    if not etag is None:
        try:
            with open(ETAG_CACHE_FILE, "w", encoding="utf-8") as fout:
                fout.write(etag)
        except IOError:
            pass


def new_index_acquired():
    """
    Return True if the repology.json file is new and successfully
    downloaded.  If the file is unchanged since the last run, False
    is returned.
    """
    rawgh = "https://raw.githubusercontent.com/Ravenports/Ravenports"
    url = rawgh + "/refs/heads/master/Mk/Misc/repology.json"
    last_etag = get_cached_etag()
    headers = {
        "User-Agent": "Ravenports Vulnerability Agent",
        "Accept": "application/json",
    }
    if last_etag:
        headers["If-None-Match"] = last_etag

    req = urllib.request.Request(url, headers=headers)
    try:
        with urllib.request.urlopen(req) as response:
            if response.status == 200:
                with open(REPOLOGY_FILE, "w", encoding="utf-8") as fout:
                    fout.write(response.read().decode("utf-8"))
                response_etag = response.headers.get("ETag")
                if response_etag:
                    write_etag_cache(response_etag)
                return True

            print(f"Unrecognized response status {response.status}")

    except urllib.error.HTTPError as e:
        # typical for response "304 Not Modified"
        if e.code != 304:
            print("HTTP Error:", e.code, e.msg, e.headers)
    except urllib.error.URLError as e:
        print("URL Error:", e.reason)
    return False


def get_unique_cpenames():
    """
    Parse JSON data, and assemble unique array of CPE strings
    """
    try:
        with open(REPOLOGY_FILE, "r", encoding="utf-8") as fin:
            data = json.load(fin)
    except IOError:
        return []
    except json.JSONDecodeError:
        print("Error decoding JSON from repology data")
        return []

    # cpe => cpe:2.3:a:rubyzip_project:rubyzip:2.4.1:::::ruby:x64

    cpenames = []
    for port in data["ravenports"]:
        if "cpe" in port:
            work = port["cpe"]["vendor"] + ":" + port["cpe"]["product"] + ":"
            work = work + port["version"] + ":*:*:*:*:"
            if "target_sw" in port["cpe"]:
                work = work + port["cpe"]["target_sw"] + ":*:*"
            else:
                work = work + "*:*:*"
            if not work in cpenames:
                cpenames.append(work)
    return cpenames


def main():
    """
    Script entry point
    """
    if not new_index_acquired():
        return

    print("New index acquired")
    cpe_data = get_unique_cpenames()
    print(len(cpe_data))
    # os.remove(REPOLOGY_FILE)


if __name__ == "__main__":
    main()
